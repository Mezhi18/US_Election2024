---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
```

```{r}
#| include: false
#| warning: false
#| message: false


#Load and clean data
data <- read.csv("../data/01-raw_data/raw_data.csv") |>
  clean_names()
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Filter NYT polls and remove entries with NA or empty value for statr
# Select imporntat variables (change as you please)

#& !is.na(state) & state != ""

preddata <- data %>%
  filter(pollster_id == 1424) %>%
  select(display_name, question_id, sample_size, state, party, answer, candidate_id, candidate_name, pct, start_date, end_date)

```

```{r}
#| echo: false
#| warning: false
#| message: false

#FILTERED SWING STATES, SUBJECT TO CHANGE, ALSO INCLUDED NATIONAL?
harrisdata <- preddata %>%
  filter(state %in% c("Georgia", "Arizona", "Nevada", "Michigan", "North Carolina", "Pennsylvania", "Wisconsin")) %>%
  filter(candidate_name == "Kamala Harris") %>%
  mutate(
    end_date = mdy(end_date)    #is date mutated correctly here 
  ) %>%
  
  # Step 4: Filter by date and calculate number of respondents
  filter(end_date >= as.Date("2024-07-21")) %>%
  mutate(
    num_harris = round((pct / 100) * sample_size, 0)
  )

harrisdata

#### Plot data ####
base_plot <- ggplot(harrisdata, aes(x = end_date, y = pct)) +
  theme_classic() +
  labs(y = "Harris percent", x = "Date") +
    theme(legend.position = "bottom")

# Plots poll estimates and overall smoothing
base_plot +
  geom_point() +
  geom_smooth()

# This gets messy - need to add a filter - see line 21
base_plot +
  geom_point(aes(color = state)) +
  geom_smooth() +
  theme(legend.position = "bottom")

```

```{r}
#| include: false
#| warning: false
#| message: false

## MODEL 1, BAYESIAN MODEL WITH PREDICTOR STATE

# Define Model
model1 <- cbind(num_harris, sample_size - num_harris) ~ (1 | state)

priors <- normal(0, 2.5, autoscale = TRUE)

bayesian_model1 <- stan_glmer(
  formula = model1,
  data = harrisdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)

```

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for model 1
pp_check(bayesian_model1)
summary(bayesian_model1)
plot(bayesian_model1, pars = "(Intercept)", prob = 0.95)
print(modelsummary(bayesian_model1))
```

```{r}
#| include: false
#| warning: false
#| message: false

## MODEL 2, BAYESIAN MODEL WITH PREDICTOR END_DATE AND STATE

# Turn end_date into quantifiable column, to use for model
harrisdata <- harrisdata %>%
  mutate(
    end_date_num = as.numeric(end_date - min(end_date)))

harrisdata <- harrisdata |>
  mutate(state = factor(state))

# Define Model 2
model2 <- cbind(num_harris, sample_size - num_harris) ~ (1 | end_date_num) + (1 | state)

bayesian_model2 <- stan_glmer(
  formula = model2,
  data = harrisdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for Model 2
pp_check(bayesian_model2)
summary(bayesian_model2)
plot(bayesian_model2, pars = "(Intercept)", prob = 0.95)
print(modelsummary(bayesian_model2))
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Predict and plot

spline_model_pred <- stan_glm(
  pct ~ ns(end_date_num, df = 5) + state,
  data = harrisdata,
  family = gaussian(),
  prior = normal(0, 5),
  prior_intercept = normal(50, 10),
  seed = 1234,
  iter = 2000,
  chains = 4,
  refresh = 0
)

# Summarize the model
summary(spline_model_pred)

# Posterior predictive checks
pp_check(spline_model_pred)
```

```{r}

new_data <- data.frame(
  end_date_num = seq(
    min(harrisdata$end_date_num),
    max(harrisdata$end_date_num),
    length.out = 100),
  state = factor("Georgia", levels = levels(harrisdata$state)))

posterior_preds <- posterior_predict(spline_model_pred, newdata = new_data)

pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975))

ggplot(harrisdata, aes(x = end_date_num, y = pct, color = state)) +
  geom_point() +
  geom_line(
    data = pred_summary,
    aes(x = end_date_num, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date_num, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE) +
  labs(
    x = "Days since earliest poll",
    y = "Percentage",
    title = "Poll Percentage over Time with Spline Fit") +
  theme_minimal()
```

# Introduction

The 2024 United States presidential election represents a pivotal moment in the country's political landscape. As in previous elections, swing states are projected to play a critical role in determining the outcome. Swing states, which are characterized by their shifting voting patterns and balanced support for both major political parties, have historically been the focus of intense campaign efforts and polling analyses. Understanding the dynamics and voter preferences in these states is crucial to gaining insight into the broader electoral trends that could shape the nation's future.

In this paper we aim to analyze polling data related to the 2024 election, with a particular emphasis on the swing states. By examining various polls and identifying patterns in voter sentiment, we seek to uncover the factors that may influence voter behavior in these highly contested regions. Our analysis will explore demographic shifts, the impact of key issues, and the level of voter engagement across different swing states. Through a comprehensive statistical approach, we aim to contribute to the understanding of the evolving electoral landscape and provide meaningful insights into the forces shaping the 2024 presidential election.

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

# Data {#sec-data}

As our paper is about the 2024 United States federal election and more specifically we are looking at the polls and the polling data comparing the two candidates, former President Donald Trump and Vice President Kamala Harris, for the upcoming election. Our original Data set had over 16,000 unique entries from different pollsters, the business or Organization that conducts the poll. Each poll has two entries one giving the Data for the polling a opinions of Donald Trump and the second for Kamala Harris. We have acquired our polling data from @bibnotmadeyet.

As there are over 50 variables many of which are redundant to our paper we will only discuss those that we have kept in our clean data as they are the only ones we use in our analysis.

**display_name:** This column shows the name of the Pollster that conducted the poll, as we want to keep consistency we are only looking at polls conducted by the New York Times.

**question_id:** This variable refers to the question that was asked in the specific poll.

**sample_size:** This variable is the quantity of people that participated in the specific poll.

**state:** This variable tells us in which States the poll was conducted.

**party:** This variable tells us which party the poll participants intend to vot for.

**answer:** This variable tells us the candidate the participant intend to vote for.

**candidate_id:** This variable is the numerical value assigned to each candidate.

**candidate_name**: This is the full name of the selected candidate.

**pct:** This tells us the percentage of participants that intend to vote for the selected candidate.

**start_date:** The date the pollster began conducting the poll.

**end_date:** The date the pollster finished conducting the poll.

**num_harris:** The number of participants that intend to vote for Kamala Harris.

**end_date_num:** IDK

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement

Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.

Some of our data is of penguins (@fig-bills), from @palmerpenguins.

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

analysis_data |> 
  ggplot(aes(x = width, y = length)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Wing width (mm)",
       y = "Wing length (mm)")
```

Talk way more about it.

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.

# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.

```{=tex}
\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}
```
We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.

# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```

# Discussion

## Arizona {#sec-arizona}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Georgia {#sec-georgia}

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Michigan {#sec-michigan}

## Nevada {#sec-nevada}

## North Carolina {#sec-norcar}

## Michigan {#sec-michigan}

## Pennsylvania {#sec-penn}

## Wisconsin {#sec-Wisconsin}




## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

Why we choose NYT? - `numeric_grade` is 3 - `pollscore` is -1.5, a score of reliability called "Predictive Optimization of Latent skill Level in Surveys, Considering Overall Record, Empirically.", where negative numbers are better - `transparency_score` is 9, reflects pollsters transparency about their methodology (calculated based on how much information it discloses about its polls and weighted by recency) - `population_full` is 'rv', respondents are registered voters

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage

# References
