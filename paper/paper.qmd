---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/Mezhi18/US_Election2024.git](https://github.com/Mezhi18/US_Election2024.git)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format:
  pdf:
    bibliography: references.bib
    documentclass: article
    geometry: margin = 1in
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
```


# Introduction

The 2024 United States presidential election represents a pivotal moment in the country's political landscape. As in previous elections, swing states are projected to play a critical role in determining the outcome. Swing states, which are characterized by their shifting voting patterns and balanced support for both major political parties, have historically been the focus of intense campaign efforts and polling analyses. Understanding the dynamics and voter preferences in these states is crucial to gaining insight into the broader electoral trends that could shape the nation's future.

In this paper we aim to analyze polling data related to the 2024 election, with a particular emphasis on the swing states. By examining various polls and identifying patterns in voter sentiment, we seek to uncover the factors that may influence voter behavior in these highly contested regions. Our analysis will explore demographic shifts, the impact of key issues, and the level of voter engagement across different swing states. Through a comprehensive statistical approach, we aim to contribute to the understanding of the evolving electoral landscape and provide meaningful insights into the forces shaping the 2024 presidential election.

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

# Data {#sec-data}

## Overview

As our paper is about the 2024 United States federal election and more specifically we are looking at the polls and the polling data comparing the two candidates, former President Donald Trump and Vice President Kamala Harris, for the upcoming election. Our original Data set had over 16,000 unique entries from different pollsters, the business or Organization that conducts the poll. Each poll has two entries, one giving the Data for the polling opinions of Donald Trump and the second for Kamala Harris. We have acquired our polling data from @bibnotmadeyet.

As there are over 50 variables many of which are redundant to our paper we will only discuss those that we have kept in our clean data as they are the only ones we use in our analysis.

- `pollster`: Shows name of the Pollster that conducted the poll.
- `sample_size`: The number of people that participated in the specific poll.
- `state`: This variable tells us in which States the poll was conducted.
- `candidate_name`: This is the full name of the selected candidate.
- `pct`: This tells us the percentage of participants that intend to vote for the selected candidate.
- `start_date`: The date the pollster began conducting the poll.
- `end_date`: The date the pollster finished conducting the poll.

The variables that we have create are:

- `num_harris`: The number of participants that intend to vote for Kamala Harris.
- `end_date_num`: The number of days since the first poll since Harris announced her candidacy. 

Each pollster has a numeric grade from 1.0 to 3.0, which indicates the quality/ reliability of the respective pollster. Additionally, each pollster is also given a transparency score from 1.0 to 10.0 reflecting how 'transparent' the pollster is, or how much information is disclosed about its polls and methodology. It is important for pollsters to maintain high numeric grades and transparency scores because these metrics directly reflect the quality and reliability of their data. To ensure the highest level of accuracy in our predictions, we only include polls with a numeric grade of 1.5 or above and a transparency score of 6.0 or above.

Â¿ does this go into data cleaning ?

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...


## Methodology

This paper uses 'polls-of-polls' method to analyze and predict our outcome, which combines polls from multiple sources (pollsters). By combining results from various sources, this approach incorporates diverse perspectives, which helps to minimize individual biases and provides a more balanced view. Unlike relying on a single poll, which can be influenced by its own biases, the 'polls-of-polls' method enhances reliability and increases the overall validity of the results.


... explain how pollsters survey people, what their different methodologies are, and why these things are important for an accurate prediction...

## Measurement/ Data Visualization 

```{r}
#| include: false
#| warning: false
#| message: false

#Load and clean data
data <- read.csv("../data/01-raw_data/raw_data.csv") |>
  clean_names()

preddata <- data %>%
  filter(numeric_grade >1.5 & transparency_score >6) %>%
  select(pollster, sample_size, state, candidate_name, pct, start_date, end_date, pollscore, numeric_grade) %>%
  filter(!is.na(pollscore)) %>%
  filter(!is.na(state) & state != "")
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-supportstate
#| fig-cap: "Distribution of Support Percentage by State"

harrisdata <- preddata %>%
  filter(state %in% c("Georgia", "Arizona", "Nevada", "Michigan", "North Carolina", "Pennsylvania", "Wisconsin")) %>%
  filter(candidate_name == "Kamala Harris") %>%
  mutate(end_date = mdy(end_date)) %>%
  filter(end_date >= as.Date("2024-07-21")) %>%
  mutate(num_harris = round((pct / 100) * sample_size, 0))

ggplot(harrisdata, aes(x = reorder(state, pct, median), y = pct, fill = state)) +
  geom_boxplot() +
  coord_flip() +  # Flip for better readability
  labs(x = "State", y = "Support Percentage") +
  theme_minimal() +
  theme(legend.position = "none")
```
We focus on the swing states of the U.S, according to  [cite NYT PAPER]


These are the statistics of each swing state by percetnage by state. 

```{r}
#| echo: false
#| warning: false
#| message: false

#### Plot data ####
base_plot <- ggplot(harrisdata, aes(x = end_date, y = pct)) +
  theme_classic() +
  labs(y = "Harris percent", x = "Date") +
    theme(legend.position = "bottom")

base_plot +
  geom_point(aes(color = state)) +
  geom_smooth() +
  theme(legend.position = "bottom")

ggplot(harrisdata, aes(x = end_date, y = pct, color = state)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  facet_wrap(~ state, scales = "free_y") +
  labs(y = "Harris Percent", x = "Date", title = "Polling Trends for Kamala Harris by State") +
  theme_minimal()

```

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

Talk way more about it.

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.

# Model

This is Model 1, follows Bayesian Model

We define our model as:

*define each vairable here*
```{=tex}
\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \times \mbox{State}_i + \beta_2 \times \mbox{Days Since First Poll}_i + \beta_3 \times \mbox{Pollster}_i \\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Exponential}(1)
\end{align}
```

```{r}
#| include: false
#| warning: false
#| message: false

# Turn end_date into quantifiable column, to use for model
harrisdata <- harrisdata %>%
  mutate(
    end_date_num = as.numeric(end_date - min(end_date)))

harrisdata <- harrisdata |>
  mutate(state = factor(state))

# Define Model
model <- cbind(num_harris, sample_size - num_harris) ~ (1 | state) + (1 | pollster) + (1 | end_date_num)

priors <- normal(0, 2.5, autoscale = TRUE)

bayesian_model <- stan_glmer(
  formula = model,
  data = harrisdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  weights = harrisdata$numeric_grade,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95)
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for Model
pp_check(bayesian_model)
plot(bayesian_model, pars = "(Intercept)", prob = 0.95)
modelsummary::modelsummary(
  list(
    "First model" = bayesian_model
  ),
  statistic = "mad",
  fmt = 2
)
```


This is Model 2 

```{r}
#| include: false
#| warning: false
#| message: false

spline_model <- stan_glm(
  pct ~ ns(end_date_num, df = 5) + pollster + state, 
  data = harrisdata,
  family = gaussian(),
  prior = normal(0, 5),
  prior_intercept = normal(50, 10),
  seed = 1234,
  iter = 2000,
  chains = 4,
  refresh = 0
)

# Summarize the model
summary(spline_model)

# Posterior predictive checks
pp_check(spline_model)

modelsummary::modelsummary(
  list(
    "First model" = spline_model
  ),
  statistic = "mad",
  fmt = 2
)
```

```{r}
#| echo: false
#| warning: false
#| message: false


harrisdata$pollster <- factor(harrisdata$pollster)
harrisdata$state <- factor(harrisdata$state)

new_data <- data.frame(
  end_date_num = seq(
    min(harrisdata$end_date_num),
    max(harrisdata$end_date_num),
    length.out = 100
  ),
  pollster = factor("YouGov", levels = levels(harrisdata$pollster)),
  state = factor("Georgia", levels = levels(harrisdata$state)))

posterior_preds <- posterior_predict(spline_model, newdata = new_data)

pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )

# Plot data and Bayesian model predictions with confidence ribbon
ggplot(harrisdata, aes(x = end_date_num, y = pct, color = state)) +
  geom_point() +
  geom_line(
    data = pred_summary,
    aes(x = end_date_num, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date_num, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "Days since earliest poll",
    y = "Percentage",
    title = "Poll Percentage over Time"
  ) +
  facet_wrap(~ state, scales = "free_y") +
  theme_minimal()
```

# TRUMP #

```{r}
trumpdata <- preddata %>%
  filter(state %in% c("Georgia", "Arizona", "Nevada", "Michigan", "North Carolina", "Pennsylvania", "Wisconsin")) %>%
  filter(candidate_name == "Donald Trump") %>%
  mutate(end_date = mdy(end_date)) %>%
  filter(end_date >= as.Date("2024-07-21")) %>%
  mutate(num_trump = round((pct / 100) * sample_size, 0))

ggplot(trumpdata, aes(x = reorder(state, pct, median), y = pct, fill = state)) +
  geom_boxplot() +
  coord_flip() +  # Flip for better readability
  labs(x = "State", y = "Support Percentage") +
  theme_minimal() +
  theme(legend.position = "none")

trumpdata <- trumpdata %>%
  mutate(
    end_date_num = as.numeric(end_date - min(end_date)))

trumpdata <- trumpdata |>
  mutate(state = factor(state))

# Define Model
model2 <- cbind(num_trump, sample_size - num_trump) ~ (1 | state) + (1 | pollster) + (1 | end_date_num)

priors <- normal(0, 2.5, autoscale = TRUE)

bayesian_model2 <- stan_glmer(
  formula = model2,
  data = trumpdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  weights = trumpdata$numeric_grade,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95)
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for Model
pp_check(bayesian_model2)
plot(bayesian_model2, pars = "(Intercept)", prob = 0.95)
modelsummary::modelsummary(
  list(
    "First model" = bayesian_model2
  ),
  statistic = "mad",
  fmt = 2
)
```

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

### Model justification

What do we expect...
We expect a predictions in the high 40% based on our current data.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```

```{r}
harrisdata <- harrisdata %>% filter(!is.na(numeric_grade)) %>% filter(!is.na(num_harris))
trumpdata <- trumpdata %>% filter(!is.na(numeric_grade)) %>% filter(!is.na(num_trump))
trumpdata
```

```{r}
library(dplyr)
library(ggplot2)
library(rstanarm)

harris_data <- harrisdata %>%
  mutate(
    candidate_name = "Kamala Harris",
    support_ratio = num_harris  # Assuming harris_support_ratio is already calculated
  ) %>%
  select(end_date_num, candidate_name, support_ratio)

# Prepare Trump data with a unified structure
trump_data <- trumpdata %>%
  mutate(
    candidate_name = "Donald Trump",
    support_ratio = num_trump  # Assuming trump_support_ratio is already calculated
  ) %>%
  select(end_date_num, candidate_name, support_ratio)

# Combine both into a single data frame
combined_data <- bind_rows(harris_data, trump_data)

library(ggplot2)
library(ggplot2)

# Assuming `combined_data` contains columns `end_date_num`, `support_ratio`, and `candidate_name`

ggplot(combined_data, aes(x = end_date_num, y = support_ratio, color = candidate_name, fill = candidate_name)) +
  # Shaded area around each line for overlap visualization
  geom_ribbon(data = combined_data %>% filter(candidate_name == "Kamala Harris"),
              aes(ymin = support_ratio - 0.05, ymax = support_ratio + 0.05),
              alpha = 0.3, fill = "red") +
  geom_ribbon(data = combined_data %>% filter(candidate_name == "Donald Trump"),
              aes(ymin = support_ratio - 0.05, ymax = support_ratio + 0.05),
              alpha = 0.3, fill = "blue") +
  
  # Line plot for each candidate
  geom_line(aes(group = candidate_name), size = 1) +
  
  scale_color_manual(values = c("Kamala Harris" = "red", "Donald Trump" = "blue")) +  # Set line colors
  labs(
    x = "Days Since Earliest Poll", 
    y = "Support Ratio",
    color = "Candidate",
    title = "Support Ratio for Harris and Trump Over Time with Overlap Highlighted"
  ) +
  theme_minimal() +
  theme(
    text = element_text(size = 12),
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    legend.title = element_text(face = "bold")
  )

```
# Discussion

## Arizona {#sec-arizona}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Georgia {#sec-georgia}

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Michigan {#sec-michigan}

## Nevada {#sec-nevada}

## North Carolina {#sec-norcar}

## Michigan {#sec-michigan}

## Pennsylvania {#sec-penn}

## Wisconsin {#sec-Wisconsin}




## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

Why we choose NYT? - `numeric_grade` is 3 - `pollscore` is -1.5, a score of reliability called "Predictive Optimization of Latent skill Level in Surveys, Considering Overall Record, Empirically.", where negative numbers are better - `transparency_score` is 9, reflects pollsters transparency about their methodology (calculated based on how much information it discloses about its polls and weighted by recency) - `population_full` is 'rv', respondents are registered voters

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...

```{r}
#| eval: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: false
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage

# Appendix 1


# Appendix 2


=======
>>>>>>> eda40e1517683f0ad12e0bcd901797a2bb2abd7d
\newpage

# References
