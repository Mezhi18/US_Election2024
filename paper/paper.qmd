---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/Mezhi18/US_Election2024.git](https://github.com/Mezhi18/US_Election2024.git)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format:
  pdf:
    bibliography: references.bib
    documentclass: article
    geometry: margin = 1in
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
```


# Introduction

The 2024 United States presidential election represents a pivotal moment in the country's political landscape. As in previous elections, swing states are projected to play a critical role in determining the outcome. Swing states, which are characterized by their shifting voting patterns and balanced support for both major political parties, have historically been the focus of intense campaign efforts and polling analyses. Understanding the dynamics and voter preferences in these states is crucial to gaining insight into the broader electoral trends that could shape the nation's future.

In this paper we aim to analyze polling data related to the 2024 election, with a particular emphasis on the swing states. By examining various polls and identifying patterns in voter sentiment, we seek to uncover the factors that may influence voter behavior in these highly contested regions. Our analysis will explore demographic shifts, the impact of key issues, and the level of voter engagement across different swing states. Through a comprehensive statistical approach, we aim to contribute to the understanding of the evolving electoral landscape and provide meaningful insights into the forces shaping the 2024 presidential election.

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

# Data {#sec-data}

## Overview

As our paper is about the 2024 United States federal election and more specifically we are looking at the polls and the polling data comparing the two candidates, former President Donald Trump and Vice President Kamala Harris, for the upcoming election. Our original Data set had over 16,000 unique entries from different pollsters, the business or Organization that conducts the poll. Each poll has two entries, one giving the Data for the polling opinions of Donald Trump and the second for Kamala Harris. We have acquired our polling data from @fivethirtyeight2024

As there are over 50 variables many of which are redundant to our paper we will only discuss those that we have kept in our clean data as they are the only ones we use in our analysis.

- `pollster`: Shows name of the Pollster that conducted the poll.
- `sample_size`: The number of people that participated in the specific poll.
- `state`: This variable tells us in which States the poll was conducted.
- `candidate_name`: This is the full name of the selected candidate.
- `pct`: This tells us the percentage of participants that intend to vote for the selected candidate.
- `start_date`: The date the pollster began conducting the poll.
- `end_date`: The date the pollster finished conducting the poll.

The variables that we have create are:

- `num_harris`: The number of participants that intend to vote for Kamala Harris.
- `end_date_num`: The number of days since the first poll since Harris announced her candidacy. 

Each pollster has a numeric grade from 1.0 to 3.0, which indicates the quality/ reliability of the respective pollster. Additionally, each pollster is also given a transparency score from 1.0 to 10.0 reflecting how 'transparent' the pollster is, or how much information is disclosed about its polls and methodology. It is important for pollsters to maintain high numeric grades and transparency scores because these metrics directly reflect the quality and reliability of their data. To ensure the highest level of accuracy in our predictions, we only include polls with a numeric grade of 1.5 or above and a transparency score of 6.0 or above.

¿ does this go into data cleaning ?

We use the statistical programming language R [@citeR]. Our data comes from [@fivethirtyeight2024] and was cleaned, modeled and graphed, using @broom, @tidy, @rstanarm, @janitor, @lubr, @broom, @modelsummary, @splines. 


## Methodology

This paper uses 'polls-of-polls' method to analyze and predict our outcome, which combines polls from multiple sources (pollsters). By combining results from various sources, this approach incorporates diverse perspectives, which helps to minimize individual biases and provides a more balanced view. Unlike relying on a single poll, which can be influenced by its own biases, the 'polls-of-polls' method enhances reliability and increases the overall validity of the results.


... explain how pollsters survey people, what their different methodologies are, and why these things are important for an accurate prediction...

## Measurement/ Data Visualization 

```{r}
#| include: false
#| warning: false
#| message: false

#Load and clean data
data <- read.csv("../data/01-raw_data/raw_data.csv") |>
  clean_names()

preddata <- data %>%
  filter(numeric_grade >1.5 & transparency_score >6) %>%
  select(pollster, sample_size, state, candidate_name, pct, start_date, end_date, pollscore, numeric_grade) %>%
  filter(!is.na(pollscore)) %>%
  filter(!is.na(state) & state != "")
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-supportstate
#| fig-cap: "Distribution of Support Percentage by State"

harrisdata <- preddata %>%
  filter(state %in% c("Georgia", "Arizona", "Nevada", "Michigan", "North Carolina", "Pennsylvania", "Wisconsin")) %>%
  filter(candidate_name == "Kamala Harris") %>%
  mutate(end_date = mdy(end_date)) %>%
  filter(end_date >= as.Date("2024-07-21")) %>%
  mutate(num_harris = round((pct / 100) * sample_size, 0))

trumpdata <- preddata %>%
  filter(state %in% c("Georgia", "Arizona", "Nevada", "Michigan", "North Carolina", "Pennsylvania", "Wisconsin")) %>%
  filter(candidate_name == "Donald Trump") %>%
  mutate(end_date = mdy(end_date)) %>%
  filter(end_date >= as.Date("2024-07-21")) %>%
  mutate(num_trump = round((pct / 100) * sample_size, 0))

combined_data <- harrisdata %>%
  inner_join(trumpdata, by = c("state", "pollster", "sample_size", "end_date")) %>%
  mutate(
    harris_percentage = (num_harris / sample_size) * 100,
    trump_percentage = (num_trump / sample_size) * 100
  )


time_series_data <- combined_data %>%
  select(state, harris_percentage, trump_percentage) %>%
  pivot_longer(cols = c(harris_percentage, trump_percentage),
               names_to = "candidate",
               values_to = "support_percentage") %>%
  mutate(candidate = ifelse(candidate == "harris_percentage", "Harris", "Trump"))

# Plotting the support percentages side-by-side for each state
plot_data <- combined_data %>%
  pivot_longer(cols = c(harris_percentage, trump_percentage),
               names_to = "candidate",
               values_to = "support_percentage") %>%
  mutate(candidate = ifelse(candidate == "harris_percentage", "Harris", "Trump"))

# Plotting the support percentages side-by-side for each state
ggplot(plot_data, aes(x = state, y = support_percentage, fill = candidate)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  labs(
    title = "Support Percentages for Harris and Trump by State",
    x = "State",
    y = "Support Percentage"
  ) +
  scale_fill_manual(values = c("Harris" = "blue", "Trump" = "red"), name = "Candidate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

In this analysis, we examine polling trends for Kamala Harris across key swing states, focusing on recent polling data from Arizona, Georgia, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin [CITE NYT PAPER]. As shown in @fig-supportstate, which displays the support percentages for both Harris and Donald Trump side-by-side by state, the data reveals a competitive race, with relatively close support levels for both candidates in most states. While Trump has a slight edge in Arizona, Georgia, and North Carolina, Harris maintains a modest lead in Michigan, Nevada, and Pennsylvania.

Moving to @fig-supportharris, which isolates Harris's support percentages across states, we gain insight into the consistency and variability of her support. The box plot highlights states like Wisconsin and Pennsylvania, where the smaller interquartile ranges indicate less variability, suggesting that Harris's support is more stable in these regions. Conversely, states such as Nevada and Georgia show greater variability, as reflected in the larger spread of the boxes and whiskers, indicating that Harris's support fluctuates more in these areas.

```{r, fig.height= 3, fig.width= 6}
#| echo: false
#| warning: false
#| message: false
#| label: fig-supportharris
#| fig-cap:  "Support Percentage for Harris by State"

ggplot(harrisdata, aes(x = reorder(state, pct, median), y = pct, fill = state)) +
  geom_boxplot() +
  coord_flip() +  # Flip for better readability
  labs(x = "State", y = "Support Percentage") +
  theme_minimal() +
  theme(legend.position = "none")
```


To explore temporal trends, we introduce the variable `end_date_num`, representing the number of days since Harris declared her candidacy. The next figures examine support trends over time in individual states.


```{r, fig.width= 6, fig.height= 3}
#| echo: false
#| warning: false
#| message: false
#| label: fig-supportWP
#| fig-cap:  "Support Percentage for Harris by State since Harris declared as Candidate for Wisconsin and Pennsylvania"

# Filter for a subset of states to plot separately
subset1 <- harrisdata %>% filter(state %in% c("Wisconsin", "Pennsylvania"))

# Plot the first subset
ggplot(subset1, aes(x = end_date, y = pct, color = state)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  facet_wrap(~ state, scales = "free_y") +
  labs(y = "Harris Percent", x = "Date") +
  theme_minimal() +
    scale_x_date(
    date_breaks = "1 month",            # Set major breaks at monthly intervals
    date_minor_breaks = "1 week",       # Optional: add minor weekly breaks for granularity
    date_labels = "%b %d"               # Format to show abbreviated month and day (e.g., "Aug 01")
  ) +
   theme(legend.position = "none")

```
In @fig-supportWP, Pennsylvania and Wisconsin display distinct trends. In Pennsylvania, support for Harris has been relatively consistent since early September, stabilizing around 48.5%. In contrast, Wisconsin shows a peak in support in mid-September, followed by a gradual decline that stabilizes in October. These observations suggest that while Pennsylvania remains a consistent stronghold for Harris, Wisconsin’s voter sentiment may be more susceptible to fluctuations.

```{r, fig.width= 6, fig.height= 3}
#| echo: false
#| warning: false
#| message: false
#| label: fig-supportAM
#| fig-cap:  "Support Percentage for Harris by State since Harris declared as Candidate"

# Filter for the remaining states
subset2 <- harrisdata %>% filter(state %in% c( "Arizona", "Michigan"))

# Plot the second subset
ggplot(subset2, aes(x = end_date, y = pct, color = state)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  facet_wrap(~ state, scales = "free_y") +
  labs(y = "Harris Percent", x = "Date") +
  theme_minimal() +
      scale_x_date(
    date_breaks = "1 month",
    date_minor_breaks = "1 week",
    date_labels = "%b %d" 
  ) +
   theme(legend.position = "none")
```
@fig-supportAM further examines Harris's support trends in Arizona and Michigan. Both states exhibit an upward trend in support starting in early October, which may suggest increasing favorability or strategic campaign efforts in these regions. This upward trajectory could indicate an opportunity for Harris to solidify her support in these competitive areas.

```{r, fig.width= 7, fig.height= 3}
#| echo: false
#| warning: false
#| message: false
#| label: fig-supportGNN
#| fig-cap:  "Support Percentage for Harris by State since Harris declared as Candidate"

subset3 <- harrisdata %>% filter(state %in% c("Georgia", "North Carolina", "Nevada"))

# Plot the first subset
ggplot(subset3, aes(x = end_date, y = pct, color = state)) +
  geom_point() +
  geom_smooth(se = TRUE) +
  facet_wrap(~ state, scales = "free_y") +
  labs(y = "Harris Percent", x = "Date") +
  theme_minimal() +
        scale_x_date(
    date_breaks = "1 month",
    date_minor_breaks = "1 week",
    date_labels = "%b %d" 
  ) +
   theme(legend.position = "none")
```
In @fig-supportGNN, we analyze Georgia, Nevada, and North Carolina. Nevada demonstrates the highest variability in Harris's support, which could reflect the state’s dynamic political response to recent campaign efforts. Georgia shows a steady upward trend, indicating growing support for Harris, while North Carolina reveals a slight decline since October, suggesting a possible shift in voter support.

Overall, these visualizations illustrate that voter support for Harris varies significantly across states and over time. Notably, many states exhibit shifts in mid-September, indicating that voter opinions are sensitive to external factors or campaign dynamics during this period. This temporal variable, alongside state-specific characteristics, will inform the predictive model to better understand and forecast support for Harris in key regions.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

Talk way more about it.

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.

# Model

We define our model as:

```{=tex}
\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \times \mbox{State}_i + \beta_2 \times \mbox{Pollster}_i + \beta_3 \times \mbox{Days since first poll}_i\\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Exponential}(1)
\end{align}
```


We used the `stan_glmer` function from `rstanarm` package to create a Bayesian regression model with a Normal distribution. The dependent variable in the proportion of respondent who support Kamala Harris, and our model aims to predict Harris' support based on several importnat factors, modeled by: 

```{r}
#| include: false
#| warning: false
#| message: false

# Turn end_date into quantifiable column, to use for model
harrisdata <- harrisdata %>%
  mutate(
    end_date_num = as.numeric(end_date - min(end_date)),
        state = factor(state))

# Define Model
model <- cbind(num_harris, sample_size - num_harris) ~ (1 | state) + (1 | pollster) + (1 | end_date_num)

priors <- normal(0, 2.5, autoscale = TRUE)

bayesian_model <- stan_glmer(
  formula = model,
  data = harrisdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  # weights = harrisdata$numeric_grade,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95)
```

where:

- $y_i$ is the dependent variable, represneting the proportion of respondents who support Harris
- $\beta_0$ is the intercept term, representing the expected proportion of $y_i$ when all other predictors are set to zero.
- $\beta_1$ corresponds to the `state` choosing one of seven states,
- $\beta_2$ corresponds to the `pollster`,
- $\beta_3$ is the value representing number of days since the first poll. 

All variables follow the normal distribution with a mean of 0 and a standard deviation of 2.5. 

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for Model
pp_check(bayesian_model)
plot(bayesian_model, pars = "(Intercept)", prob = 0.95)
modelsummary::modelsummary(
  list(
    "First model" = bayesian_model
  ),
  statistic = "mad",
  fmt = 2
)
```

```{r}
#| echo: false
#| warning: false
#| message: false

harrisdata <- harrisdata %>% drop_na()
expected_probs <- posterior_epred(bayesian_model, newdata = harrisdata)
median_probs <- apply(expected_probs, 2, median)
harrisdata <- harrisdata %>%
  mutate(median_prob = median_probs)


ggplot(harrisdata, aes(x = end_date_num, y = median_prob, color = state)) +
  geom_line(alpha = 0.5) +  # Plot raw data with some transparency to show noise
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs", k = 10), se = FALSE) +  # Smoother with flexible spline
  labs(
    title = "Predicted Probability of Harris Outcome Over Time by State",
    x = "Days Since First Poll (end_date_num)",
    y = "Predicted Probability"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ state, scales = "free_y")


ggplot(harrisdata, aes(x = end_date_num, y = median_prob, color = state)) +
  geom_line(alpha = 0.5) +  # Plot raw data with some transparency
  geom_smooth(method = "loess", span = 0.3, se = FALSE) +  # Add a less smoothed trend line
  labs(
    title = "Predicted Probability of Harris Outcome Over Time by State",
    x = "Days Since First Poll (end_date_num)",
    y = "Predicted Probability"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ state, scales = "free_y")

```
```{r}
expected_probs <- posterior_epred(bayesian_model, newdata = harrisdata)

# Calculate the mean predicted probability across all observations (overall predicted support percentage)
overall_predicted_support <- mean(rowMeans(expected_probs)) * 100
overall_predicted_support


```

```{r}
expected_probs <- posterior_epred(bayesian_model, newdata = harrisdata)

# Calculate the median predicted probability for each observation
median_probs <- apply(expected_probs, 2, median)

# Add median predicted probabilities to `harrisdata`
harrisdata <- harrisdata %>%
  mutate(median_prob = median_probs)

# Calculate the average predicted support by state
predicted_support_table <- harrisdata %>%
  group_by(state) %>%
  summarize(average_predicted_support = round(mean(median_prob) * 100,2))

# Print the table
predicted_support_table
```


The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

### Model justification

What do we expect...
We expect a predictions in the high 40% based on our current data.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```




# Discussion

## Arizona {#sec-arizona}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Georgia {#sec-georgia}

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Michigan {#sec-michigan}

## Nevada {#sec-nevada}

## North Carolina {#sec-norcar}

## Michigan {#sec-michigan}

## Pennsylvania {#sec-penn}

## Wisconsin {#sec-Wisconsin}




## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

Why we choose NYT? - `numeric_grade` is 3 - `pollscore` is -1.5, a score of reliability called "Predictive Optimization of Latent skill Level in Surveys, Considering Overall Record, Empirically.", where negative numbers are better - `transparency_score` is 9, reflects pollsters transparency about their methodology (calculated based on how much information it discloses about its polls and weighted by recency) - `population_full` is 'rv', respondents are registered voters

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...

```{r}
#| eval: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: false
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage

# Appendix 1


# Appendix 2
Here we will be talking about how we would conduct a $100,000 surevey to gather data about this upcoming election to ensure there is minimal error in the data we are collecting and, our data represents the facts we want them to represent. 
Out of the \$100,000 we will allocate \$15000 for the necessary development and administration of the data. This means we will be spending this money to create the survey, and have a infrastructure in place to hold the large amount of data as well as cover any security fees to keep this data private and safe. Then we allocate $50000 to advertise the survey. We will need a large sample so we will be spending most of our budget for this. We will have a different urls for each advertisement we have so that we can incorporate this in our data to see which demographic is accessing the survey through which platform. The platforms to advertise this is through spotify, facebook, instagram, and some news networks. If possible we will try to use this money to get it endorsed by branches of government to show our reliability. Reliability is also what citizens respond to so this will get a lot of respondants. We will spend \$25,000 for modeling our data as they tend to be expensive with data this size. And the rest of the \$15,000 will be leftover cost for anything that we don't foresee. If there is any leftover we can add a survey participation price such as having a free 3 month trial for the platforms we mentioned above (that is if they have a subscription based membership). 

We will not be using telephone surveys because according to reserach [@idSurvey] we find the most people, don't pick up calls from unknown numbers and even the people that pick it up they are less inclined to answer the questions of the survey. 

Next to look at the actual contents of the survey. They can be accessed through this link:[Sample survey question](https://forms.office.com/Pages/ResponsePage.aspx?id=JsKqeAMvTUuQN7RtVsVSEL7G89G56QlHp_qqIPzGbJdUME9UQzJaWUlCVldZTktRV09UQ0Q3N0hQRi4u). There are 3 things that we were careful of when we were creating this survey. First thing we considered was transperency. People need the reassurence that the data that is being collected will not be used against them, and so we teel them what data we do collect and how the data we collect cannot be used to identify a person. The second thing we focus on is readability of the questions. We tried to make them as simple as possible using accessibile language, and tried to keep it short as well (@Tourangeau_Rips_Rasinski_2000). We also prioritised the size of the survey. We kept it to a short 11 questions that will tell us their political standing in the past and present. We know what current issues are important to them as well as their age group and the state they are from. This will help us gather data without inconveniencing the person. 

Finally we take a look at how we sample from the gathered data. We thought about random sampling but we were worried about having unequal proportions of the demographic we would advertise to. So if more people that go to facebook responded, that doesn't necessairly mean that people use facebook more than the other platforms. So we we decided to combine startified and cluster  sampling(@annurev). The idea is that we will choose based on the different platforms we advertise to first to have a cluster sampling method. And then we will sample the data by dividing the people by the certain aspects of the surevy, like if they are in different age groups or if they are registered voters. This is called Stratified Sampling (@annurev). Then we take a union of all the samples and we gather a group that we are able to build models based off of. 

# References
