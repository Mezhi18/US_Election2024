---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/Mezhi18/US_Election2024.git](https://github.com/Mezhi18/US_Election2024.git)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---



```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
```

```{r}
#| include: false
#| warning: false
#| message: false

#Load and clean data
data <- read.csv("../data/01-raw_data/raw_data.csv") |>
  clean_names()
```


```{r}
#| echo: false
#| warning: false
#| message: false

# Filter NYT polls and remove entries with NA or empty value for statr
# Select imporntat variables (change as you please)

#& !is.na(state) & state != ""

preddata <- data %>%
  filter(pollster_id == 1424) %>%
  select(display_name, question_id, sample_size, state, party, answer, candidate_id, candidate_name, pct, start_date, end_date)

print(preddata)
```

```{r}
#| echo: false
#| warning: false
#| message: false

#FILTERED SWING STATES, SUBJECT TO CHANGE, ALSO INCLUDED NATIONAL?
harrisdata <- preddata %>%
  filter(state %in% c("Georgia", "Arizona", "Nevada", "Michigan", "North Carolina", "Pennsylvania", "Wisconsin")) %>%
  filter(candidate_name == "Kamala Harris") %>%
  mutate(
    end_date = mdy(end_date)    #is date mutated correctly here 
  ) %>%
  
  # Step 4: Filter by date and calculate number of respondents
  filter(end_date >= as.Date("2024-07-21")) %>%
  mutate(
    num_harris = round((pct / 100) * sample_size, 0)
  )

harrisdata

#### Plot data ####
base_plot <- ggplot(harrisdata, aes(x = end_date, y = pct)) +
  theme_classic() +
  labs(y = "Harris percent", x = "Date") +
    theme(legend.position = "bottom")

# Plots poll estimates and overall smoothing
base_plot +
  geom_point() +
  geom_smooth()

# This gets messy - need to add a filter - see line 21
base_plot +
  geom_point(aes(color = state)) +
  geom_smooth() +
  theme(legend.position = "bottom")

```


```{r}
#| echo: false
#| warning: false
#| message: false

## MODEL 1, BAYESIAN MODEL WITH PREDICTOR STATE

# Define Model
model1 <- cbind(num_harris, sample_size - num_harris) ~ (1 | state)

priors <- normal(0, 2.5, autoscale = TRUE)

bayesian_model1 <- stan_glmer(
  formula = model1,
  data = harrisdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)

```

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for model 1
pp_check(bayesian_model1)
summary(bayesian_model1)
plot(bayesian_model1, pars = "(Intercept)", prob = 0.95)
print(modelsummary(bayesian_model1))
```


```{r}
#| include: false
#| warning: false
#| message: false

## MODEL 2, BAYESIAN MODEL WITH PREDICTOR END_DATE AND STATE

# Turn end_date into quantifiable column, to use for model
harrisdata <- harrisdata %>%
  mutate(
    end_date_num = as.numeric(end_date - min(end_date)))

harrisdata <- harrisdata |>
  mutate(state = factor(state))

# Define Model 2
model2 <- cbind(num_harris, sample_size - num_harris) ~ (1 | end_date_num) + (1 | state)

bayesian_model2 <- stan_glmer(
  formula = model2,
  data = harrisdata,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 4,
  adapt_delta = 0.95
)
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Plot checks for Model 2
pp_check(bayesian_model2)
summary(bayesian_model2)
plot(bayesian_model2, pars = "(Intercept)", prob = 0.95)
print(modelsummary(bayesian_model2))
```

```{r}
#| echo: false
#| warning: false
#| message: false

# Predict and plot

spline_model_pred <- stan_glm(
  pct ~ ns(end_date_num, df = 5) + state,
  data = harrisdata,
  family = gaussian(),
  prior = normal(0, 5),
  prior_intercept = normal(50, 10),
  seed = 1234,
  iter = 2000,
  chains = 4,
  refresh = 0
)

# Summarize the model
summary(spline_model_pred)

# Posterior predictive checks
pp_check(spline_model_pred)
```

```{r}

new_data <- data.frame(
  end_date_num = seq(
    min(harrisdata$end_date_num),
    max(harrisdata$end_date_num),
    length.out = 100),
  state = factor("Georgia", levels = levels(harrisdata$state)))

posterior_preds <- posterior_predict(spline_model_pred, newdata = new_data)

pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975))

ggplot(harrisdata, aes(x = end_date_num, y = pct, color = state)) +
  geom_point() +
  geom_line(
    data = pred_summary,
    aes(x = end_date_num, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date_num, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE) +
  labs(
    x = "Days since earliest poll",
    y = "Percentage",
    title = "Poll Percentage over Time with Spline Fit") +
  theme_minimal()
```





# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.




## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}


## Posterior predictive check

Why we choose NYT?
- `numeric_grade` is 3
- `pollscore` is -1.5, a score of reliability called "Predictive Optimization of Latent skill Level in Surveys, Considering Overall Record, Empirically.", where negative numbers are better
- `transparency_score` is 9, reflects pollsters transparency about their methodology (calculated based on how much information it discloses about its polls and weighted by recency)
- `population_full` is 'rv', respondents are registered voters 


In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage

# Appendix 1


# Appendix 2


\newpage


# References


